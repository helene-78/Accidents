{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8-ZUrywWMjZH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE # Pour avoir 50 % de 0 et 50 % de 1 dans la colonne presence_accident\n",
    "from sklearn.linear_model import LogisticRegression # Regression logistique\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RepeatedKFold #KFold répété, pour mieux entraîner le modèle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns #Tableau des corrélations\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px # Pour faire des graphes dans l'interface Dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5phrpM9SL0O"
   },
   "source": [
    "**Importation du dataframe df_utiles traité dans prep_df_utiles.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GpmsJOB1UVKz"
   },
   "outputs": [],
   "source": [
    "df_utiles = pd.read_csv(\"df_utiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utiles['lat'] = df_utiles['lat'].str.replace(',', '.').astype(float)\n",
    "df_utiles['long'] = df_utiles['long'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Pour avoir les coordonnées GPS en float, sinon plotly.express (px) ne peut pas les afficher sur la carte de France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZkoK0wWVyQj",
    "outputId": "b134f55f-14f3-4dbf-9bd9-047f7759268c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'jour', 'mois', 'an', 'hrmn', 'lum', 'dep', 'agg', 'int',\n",
       "       'atm', 'col', 'lat', 'long', 'place', 'catu', 'grav', 'sexe', 'an_nais',\n",
       "       'trajet', 'secu1', 'secu2', 'secu3', 'locp', 'actp', 'etatp', 'catr',\n",
       "       'circ', 'nbv', 'vosp', 'prof', 'pr', 'pr1', 'plan', 'surf', 'infra',\n",
       "       'situ', 'vma', 'senc', 'catv', 'obs', 'obsm', 'choc', 'manv', 'motor',\n",
       "       'presence_deces'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_utiles.columns # Liste des colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoAxBCR2xwEq"
   },
   "source": [
    "**Analyse statistique des données de df_utiles.csv : matrice des corrélations (en commentaire car fait planter Jupyter)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "Wt_opqQix0Pm",
    "outputId": "09800f70-8d3f-4513-deab-14aeaa8a9856"
   },
   "outputs": [],
   "source": [
    "#corr = df_utiles.drop(['an', 'presence_deces'], axis=1).corr()\n",
    "#f, ax = plt.subplots(figsize=(11, 9))\n",
    "#cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "#sns.heatmap(corr, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdzSAkdxOhPx"
   },
   "source": [
    "**Test ARIMA pour anticiper nbre accidents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwk0OEZcWQZy",
    "outputId": "2576afc4-9634-439e-914c-16656f2e2481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\thomas\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Invalid requirement: '#statsmodels,'\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\thomas\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\thomas\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\thomas\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels #statsmodels, pour utiliser le module de séries temp SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "chyVVfATOlhV"
   },
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX # SARIMAX = modèle de séries temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRYIlFZxXxAn"
   },
   "source": [
    "**But : obtenir la colonne nbre_acc_j qui représente le nombre d'accidents par jour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "id": "zaUxXbT0OpAA",
    "outputId": "11cfb892-12bf-4239-c32f-5e43d5b647c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "df_utiles = pd.read_csv('df_utiles.csv')\n",
    "# la colonne \"jour_format_normal\" contient la date au format standard dd/mm/yyyy\n",
    "df_utiles[\"jour_format_normal\"] = 0 # Initialisation de la colonne\n",
    "df_utiles[\"jour_format_normal\"] = df_utiles[\"jour\"].astype(str)+'/'+df_utiles[\"mois\"].astype(str)+'/'+df_utiles[\"an\"].astype(str)\n",
    "df_utiles[\"jour_format_normal\"] = pd.to_datetime(df_utiles[\"jour_format_normal\"], format=\"%d/%m/%Y\")\n",
    "df_utiles[\"colonne_soustraction\"] = date(df_utiles[\"an\"].iloc[0], 1, 1) # Création d'une colonne remplie avec la date du 01/01/2019\n",
    "df_utiles[\"colonne_soustraction\"] = pd.to_datetime(df_utiles[\"colonne_soustraction\"]) #Pour transformer en objet date \n",
    "df_utiles[\"nbre_j\"] = df_utiles[\"jour_format_normal\"] - df_utiles[\"colonne_soustraction\"] # Permet d'obtenir une colonne contenant, pour chaque accident,\n",
    "# Le nombre de jours écoulés depuis le 01/01/2019\n",
    "\n",
    "def datification(x):\n",
    "    return x.days # Permet d'obtenir l'entier contenu par l'objet \"date\" de Python\n",
    "df_utiles[\"nbre_j\"] = df_utiles[\"nbre_j\"].apply(datification) #Maintenant nbre_j est une colonne d'entiers\n",
    "nbre_acc_j = df_utiles.groupby(['nbre_j']).agg('count').jour.values #Nbre d'accidents (ou de victimes d'accidents jsp) par jour\n",
    "ts = pd.Series(nbre_acc_j, index=pd.date_range(\"1/1/2019\", periods=365)) # Objet Series de pandas, pour faire des graphes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bltALNZJX70n"
   },
   "source": [
    "**SARIMAX : prédire nbre d'accidents en s'appuyant sur les données déjà enregistrées**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGSOF5ZeY4hn"
   },
   "source": [
    "**Graphe d'autocorrélation (les deux dernières lignes de code font planter Jupyter donc sont en commentaire)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "RcBVMkcAX7Z8",
    "outputId": "6366f251-4b29-4389-ae0f-a62bbc64c3d3"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Subtract the rolling mean\n",
    "nbre_acc_j_dataframe = pd.DataFrame(nbre_acc_j)\n",
    "nbre_acc_rolling = nbre_acc_j_dataframe - nbre_acc_j_dataframe.rolling(15).mean()\n",
    "\n",
    "# Drop the NaN values\n",
    "nbre_acc_rolling = nbre_acc_rolling.dropna()\n",
    "\n",
    "# Create figure and subplots\n",
    "#fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the ACF\n",
    "#plot_acf(nbre_acc_rolling, lags=25, zero=False, ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPePWfiJZCXp"
   },
   "source": [
    "Conclusion : la composante saisonale a pour période 7 (abscisse du max sur le plot ci-dessus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x3sRVwcrZSuh",
    "outputId": "67ed0764-cc55-4bfd-e749-b35c3c84fe32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>                 <td>y</td>               <th>  No. Observations:  </th>    <td>365</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>           <td>SARIMAX(5, 0, 0)x(1, 1, 0, 7)</td> <th>  Log Likelihood     </th> <td>-1939.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                  <td>Wed, 22 Dec 2021</td>        <th>  AIC                </th> <td>3892.884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                      <td>11:01:33</td>            <th>  BIC                </th> <td>3920.048</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                        <td>0</td>               <th>  HQIC               </th> <td>3903.687</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                            <td> - 365</td>             <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>              <td>opg</td>              <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1</th>   <td>    0.2613</td> <td>    0.052</td> <td>    5.074</td> <td> 0.000</td> <td>    0.160</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L2</th>   <td>    0.1273</td> <td>    0.057</td> <td>    2.221</td> <td> 0.026</td> <td>    0.015</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L3</th>   <td>    0.0943</td> <td>    0.055</td> <td>    1.725</td> <td> 0.085</td> <td>   -0.013</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L4</th>   <td>    0.0820</td> <td>    0.058</td> <td>    1.416</td> <td> 0.157</td> <td>   -0.031</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L5</th>   <td>    0.0144</td> <td>    0.056</td> <td>    0.256</td> <td> 0.798</td> <td>   -0.096</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.S.L7</th> <td>   -0.3782</td> <td>    0.051</td> <td>   -7.450</td> <td> 0.000</td> <td>   -0.478</td> <td>   -0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th>  <td> 2961.9202</td> <td>  210.258</td> <td>   14.087</td> <td> 0.000</td> <td> 2549.822</td> <td> 3374.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>0.00</td> <th>  Jarque-Bera (JB):  </th> <td>4.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.98</td> <th>  Prob(JB):          </th> <td>0.13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>1.49</td> <th>  Skew:              </th> <td>-0.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.03</td> <th>  Kurtosis:          </th> <td>3.46</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                     SARIMAX Results                                     \n",
       "=========================================================================================\n",
       "Dep. Variable:                                 y   No. Observations:                  365\n",
       "Model:             SARIMAX(5, 0, 0)x(1, 1, 0, 7)   Log Likelihood               -1939.442\n",
       "Date:                           Wed, 22 Dec 2021   AIC                           3892.884\n",
       "Time:                                   11:01:33   BIC                           3920.048\n",
       "Sample:                                        0   HQIC                          3903.687\n",
       "                                           - 365                                         \n",
       "Covariance Type:                             opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "ar.L1          0.2613      0.052      5.074      0.000       0.160       0.362\n",
       "ar.L2          0.1273      0.057      2.221      0.026       0.015       0.240\n",
       "ar.L3          0.0943      0.055      1.725      0.085      -0.013       0.201\n",
       "ar.L4          0.0820      0.058      1.416      0.157      -0.031       0.195\n",
       "ar.L5          0.0144      0.056      0.256      0.798      -0.096       0.125\n",
       "ar.S.L7       -0.3782      0.051     -7.450      0.000      -0.478      -0.279\n",
       "sigma2      2961.9202    210.258     14.087      0.000    2549.822    3374.019\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                 4.15\n",
       "Prob(Q):                              0.98   Prob(JB):                         0.13\n",
       "Heteroskedasticity (H):               1.49   Skew:                            -0.13\n",
       "Prob(H) (two-sided):                  0.03   Kurtosis:                         3.46\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Create a SARIMAX model\n",
    "model = SARIMAX(nbre_acc_j, order=(5, 0, 0), seasonal_order=(1, 1, 0, 7)) # Le 7 correspond à la période déterminée ci-dessus\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "kz1FboMAvQri",
    "outputId": "82c38d35-ebed-43c4-b65f-ab650219544c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "2019-01-01  263.000000\n",
      "2019-01-02  239.000000\n",
      "2019-01-03  255.000000\n",
      "2019-01-04  298.000000\n",
      "2019-01-05  287.000000\n",
      "...                ...\n",
      "2020-01-27  288.703401\n",
      "2020-01-28  285.480236\n",
      "2020-01-29  209.320611\n",
      "2020-01-30  274.991159\n",
      "2020-01-31  317.720738\n",
      "\n",
      "[396 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "results_pred = results.get_forecast(31) #Utilise le modèle précédent afin de prédire 31 nouvelles valeurs (mois de janvier 2020)\n",
    "results_mean = results_pred.predicted_mean #Je ne sais pas trop\n",
    "results_mean = pd.DataFrame(results_mean) #En objet dataframe\n",
    "results_final = nbre_acc_j_dataframe.append(results_mean) #On adjoint les 31 prédictions aux valeurs réelles afin de tout afficher\n",
    "results_final = results_final.reset_index() #Après cette fusion de dataframe, l'index est cassé, on le réinitialise donc\n",
    "results_final = results_final.drop(\"index\", axis=1) #La commande précédent ajoute une colonne \"index\" inutile dans le DataFrame, on la supprime\n",
    "date_index = pd.date_range('1/1/2019', periods=396, freq='D') #Pour avoir les dates en abscisse (365 + 31 = 396 jours)\n",
    "results_final = results_final.set_index(date_index)\n",
    "print(results_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des frontières des régions françaises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRiu7jxHlbkk",
    "outputId": "3ea7d739-543f-4515-dddb-4bb4b5e38d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  jour  mois    an  hrmn  lum  dep  agg  int  atm  ...  \\\n",
      "0                0    30    11  2019    60    4   93    1    1    1  ...   \n",
      "1                1    30    11  2019    60    4   93    1    1    1  ...   \n",
      "2                2    30    11  2019    60    4   93    1    1    1  ...   \n",
      "3                3    30    11  2019   120    3   93    1    1    1  ...   \n",
      "4                4    28    11  2019   900    1   92    1    1    1  ...   \n",
      "...            ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...   \n",
      "132972      132972    27    11  2019   420    1   67    1    1    8  ...   \n",
      "132973      132973    30    11  2019   120    4   94    1    1    1  ...   \n",
      "132974      132974    30    11  2019   900    1   78    1    1    1  ...   \n",
      "132975      132975    29    11  2019  1200    3   92    1    1    1  ...   \n",
      "132976      132976    29    11  2019  1200    3   92    1    1    1  ...   \n",
      "\n",
      "        catv obs obsm  choc  manv  motor  presence_deces  jour_format_normal  \\\n",
      "0          7   0    2     5    23      1               0          2019-11-30   \n",
      "1          7   0    2     5    23      1               0          2019-11-30   \n",
      "2         17   1    0     3    11      1               0          2019-11-30   \n",
      "3          7   4    0     1     0      1               0          2019-11-30   \n",
      "4          7   0    2     1     2      1               0          2019-11-28   \n",
      "...      ...  ..  ...   ...   ...    ...             ...                 ...   \n",
      "132972     7   0    2     1     2      1               0          2019-11-27   \n",
      "132973     7   3    0     1    21      0               0          2019-11-30   \n",
      "132974    33   0    0     7     1      1               0          2019-11-30   \n",
      "132975    10   0    2     4     0      2               0          2019-11-29   \n",
      "132976    10   0    2     1     0      1               0          2019-11-29   \n",
      "\n",
      "        colonne_soustraction  nbre_j  \n",
      "0                 2019-01-01     333  \n",
      "1                 2019-01-01     333  \n",
      "2                 2019-01-01     333  \n",
      "3                 2019-01-01     333  \n",
      "4                 2019-01-01     331  \n",
      "...                      ...     ...  \n",
      "132972            2019-01-01     330  \n",
      "132973            2019-01-01     333  \n",
      "132974            2019-01-01     333  \n",
      "132975            2019-01-01     332  \n",
      "132976            2019-01-01     332  \n",
      "\n",
      "[132977 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "fr_regions = pd.read_json('https://france-geojson.gregoiredavid.fr/repo/regions.geojson')\n",
    "fr_regions = fr_regions.to_json()\n",
    "print(df_utiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_utiles_regr = ['nbre_j', 'hrmn', 'lum', 'lat', 'long', 'agg', 'int', 'atm', 'col', 'catr', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ', 'catv', 'obs', 'obsm', 'choc', 'manv', 'catu', 'sexe', 'presence_deces']\n",
    "variables_utiles = ['nbre_j', 'hrmn', 'lum', 'lat', 'long', 'agg', 'col', 'prof', 'vma', 'catu', 'sexe']\n",
    "variables_utiles_utiles = ['nbre_j', 'hrmn', 'lum', 'lat', 'long', 'agg', 'col', 'prof', 'vma', 'catu', 'sexe', 'presence_deces']\n",
    "\n",
    "def regression_logistique(var_choisies, pred):\n",
    "    df_rayon = []\n",
    "    df_rayon = df_utiles[variables_utiles_utiles]\n",
    "    df_rayon = pd.DataFrame(df_rayon)\n",
    "    X = df_rayon[variables_utiles]\n",
    "    y = df_rayon.presence_deces #colonne \"presence_deces\"\n",
    "    #print(y)\n",
    "    y = y.astype(int)\n",
    "    os = SMOTE(random_state=0) #Initialisation de SMOTE, pour avoir 50 % de 0 et 50 % de 1 dans y (sans modifier la distribution de l'échantillon d'accidents)\n",
    "    cv = RepeatedKFold(n_splits=3, n_repeats=3, random_state=1) #K-Fold répété, augmente la précision de l'algo de ~10 %\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train,y_train=os.fit_resample(X_train, y_train) #On applique OS initialisé plus tôt\n",
    "    #X_train = pd.DataFrame(data=X_train)\n",
    "    #y_train= pd.DataFrame(data=y_train)\n",
    "    logreg = LogisticRegression(solver='lbfgs') # Initialisation de la régression logistique\n",
    "    logreg.fit(X_train, y_train) # Fitting sur l'ensemble de train\n",
    "    y_pred = logreg.predict(X_test) # Prédictions\n",
    "    #print(y_pred)\n",
    "    #print(logreg.coef_)\n",
    "    #print('Précision de la classification par régression logistique : ',logreg.score(X_test, y_test)*100,\"%\")\n",
    "    pred_pred = logreg.predict(pred)\n",
    "    precision_pred = max(logreg.predict_proba(pred)[0][0], logreg.predict_proba(pred)[0][1])*100\n",
    "    return [pred_pred, precision_pred, logreg.score(X_test, y_test)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Gy5nu_jrVIp",
    "outputId": "feccd22d-f4ae-4f6a-ef28-a762b1ebf4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Dec/2021 11:04:55] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:04:57] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:04:57] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:04:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:08] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:08] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:10] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:11] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Dec/2021 11:05:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1079, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1010, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"C:\\Users\\thomas\\AppData\\Local\\Temp/ipykernel_5288/1120572250.py\", line 52, in cb_render\n",
      "    res = regression_logistique(variables_utiles, (np.reshape(vals, (1, -1))))\n",
      "  File \"C:\\Users\\thomas\\AppData\\Local\\Temp/ipykernel_5288/1317332838.py\", line 18, in regression_logistique\n",
      "    X_train,y_train=os.fit_resample(X_train, y_train) #On applique OS initialisé plus tôt\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 80, in fit_resample\n",
      "    self.sampling_strategy, y, self._sampling_type\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 502, in check_sampling_strategy\n",
      "    f\"The target 'y' needs to have more than 1 class. \"\n",
      "ValueError: The target 'y' needs to have more than 1 class. Got 1 class instead\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1079, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1010, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"C:\\Users\\thomas\\AppData\\Local\\Temp/ipykernel_5288/1120572250.py\", line 52, in cb_render\n",
      "    res = regression_logistique(variables_utiles, (np.reshape(vals, (1, -1))))\n",
      "  File \"C:\\Users\\thomas\\AppData\\Local\\Temp/ipykernel_5288/1317332838.py\", line 18, in regression_logistique\n",
      "    X_train,y_train=os.fit_resample(X_train, y_train) #On applique OS initialisé plus tôt\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 80, in fit_resample\n",
      "    self.sampling_strategy, y, self._sampling_type\n",
      "  File \"C:\\Users\\thomas\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 502, in check_sampling_strategy\n",
      "    f\"The target 'y' needs to have more than 1 class. \"\n",
      "ValueError: The target 'y' needs to have more than 1 class. Got 1 class instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Dec/2021 11:05:19] \"POST /_dash-update-component HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "## Dash app (https://dash.plot.ly/getting-started)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import dash # Dash\n",
    "import dash_core_components as dcc # Pour utiliser dcc.Input (ce qui permet d'inclure les inputs dans le HTML)\n",
    "import dash_html_components as html # L'interface Dash est en HTML\n",
    "from dash.dependencies import Input, Output, State, MATCH, ALL # Pour les callbacks\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css'] # Feuille CSS externe, pour mettre en forme la dashboard\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "ALLOWED_VAR = (\n",
    "    'nbre_j', 'hrmn', 'lum', 'lat', 'long', 'agg', 'col', 'prof', 'vma', 'catu', 'sexe'\n",
    ") # Liste des variables sur lesquelles on utilise l'algo\n",
    "\n",
    "app.layout = html.Div(children=[ #Toute l'app est une balise div, qui contient des balises H1, ..., H6 (pour les titres) et des balises Div pour tous les contenus interactifs\n",
    "    html.H1(children='Prédictions'),\n",
    "    html.Div([\n",
    "        dcc.Graph(id=\"Carte\",figure=px.scatter_geo(df_utiles.head(1000), lat=\"lat\", lon=\"long\", geojson=fr_regions))] # Carte affichant les accidents sur une carte de France\n",
    "    ,style={'columnCount': 1}), \n",
    "    html.Div([\n",
    "        dcc.Graph(id=\"Prédictions\",figure=px.line(results_final, labels={'x': 'jour', 'y': 'nombre d\\'accidentés'}))] #Prédictions SARIMAX\n",
    "    ,style={'columnCount': 1}), \n",
    "    html.Div(children='''\n",
    "        Remplir les variables\n",
    "    '''),\n",
    "            html.Div( # Cette balise Div permet d'afficher les inputs sur l'interface Dash, pour qu'on puisse les remplir\n",
    "    [\n",
    "        dcc.Input(\n",
    "            id=\"input_{}\".format(_), # On identifie chaque Input par un ID \"input_nomdelavariable\", utile pour les callbacks\n",
    "            type=\"number\",\n",
    "            placeholder=\"variable {}\".format(_),\n",
    "        )\n",
    "        for _ in ALLOWED_VAR\n",
    "    ]\n",
    "    + [html.Div(id=\"out-all-types\")]\n",
    ")\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "     Output(\"out-all-types\", \"children\"),\n",
    "     [Input(\"input_{}\".format(_), \"value\") for _ in ALLOWED_VAR], # On lie les inputs affichés sur Dash et la fonction cb_render\n",
    ")\n",
    "\n",
    "def cb_render(*vals):\n",
    "    if not None in vals:\n",
    "        float_vals = []\n",
    "        for item in vals:\n",
    "            float_vals.append(float(item))\n",
    "        res = regression_logistique(variables_utiles, (np.reshape(vals, (1, -1))))\n",
    "        return \"L'algorithme prédit : {} avec une probabilité de {} et une précision de : {}\".format(res[0], res[1], res[2]) \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(host='127.0.0.1', port='8050')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression_arima.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
